{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Journal de Bord - Projet IA Prediction Reussite Scolaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jour 1 - 11/01/2026\n",
    "\n",
    "### Étapes / Actions réalisées\n",
    "- Initialisation de l'espace de travail.\n",
    "- Création des dossiers `FINAL/notebooks` pour isoler le travail des sources.\n",
    "- Copie des templates `matrice-notebook.ipynb` et `journal-de-bord.ipynb`.\n",
    "- Chargement et exploration initiale des données (`student-mat.csv`, `student-por.csv`).\n",
    "- Vérification de la structure des fichiers (séparateur `;`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations / Difficultés\n",
    "- Pas de valeurs manquantes détectées.\n",
    "- Distribution de G3 assez normale mais avec des 0 (abandons ?).\n",
    "- Forte corrélation entre G1, G2 et G3 confirmée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jour 2 - 12/01/2026\n",
    "\n",
    "### Étapes / Actions réalisées\n",
    "- Mise en place du pipeline de preprocessing : `OneHotEncoder` pour les catégories, `StandardScaler` pour les numériques.\n",
    "- Création de la fonction `train_evaluate` pour standardiser les tests.\n",
    "- Test des modèles `LinearRegression` et `RandomForestRegressor`.\n",
    "\n",
    "### Observations / Difficultés\n",
    "- Random Forest performe mieux que la Régression Linéaire.\n",
    "- Les scores R2 sont très élevés (> 0.8) car G1 et G2 sont inclus (Scénario \"Final\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jour 3 - 13/01/2026\n",
    "\n",
    "### Étapes / Actions réalisées\n",
    "- Implémentation du scénario \"Prédiction Précoce\" (sans G1 ni G2).\n",
    "- Visualisation de l'importance des variables pour Random Forest.\n",
    "- Comparaison des résultats :\n",
    "    - **Avec G1/G2** : R2 ~0.81 (RW), ~0.84 (Por)\n",
    "    - **Sans G1/G2** : R2 ~0.24 (Math), ~0.17 (Por)\n",
    "\n",
    "### Observations / Difficultés\n",
    "- La performance chute drastiquement sans les notes intermédiaires (G1, G2).\n",
    "- Prédire la note finale (G3) uniquement sur des critères socio-démographiques est difficile avec ces modèles.\n",
    "- Les variables importantes deviennent : `failures`, `absences`, `Medu`, `Fedu`.\n",
    "\n",
    "### Prochaines étapes\n",
    "- Fusionner les datasets pour analyser les élèves communs.\n",
    "- Feature Engineering pour tenter d'améliorer le scénario \"Précoce\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jour 4 - 15/01/2026\n",
    "\n",
    "### Étapes / Actions réalisées\n",
    "- Fusion des datasets Math et Portugais basée sur les attributs communs.\n",
    "- Vérification du nombre d'étudiants communs : **382**.\n",
    "- Analyse de la corrélation entre la réussite en Math (`G3_mat`) et en Portugais (`G3_por`) : **0.48**.\n",
    "- **Feature Engineering** :\n",
    "    - Création de `TotalAlc` (Dalc + Walc) : *Justifié par une corrélation forte (0.65) entre semaine/weekend et un impact identique sur G3 (-0.05)*.\n",
    "    - Création de `ParentEdu` (Medu + Fedu), `HasFailed` (failures > 0).\n",
    "    - Ré-évaluation du scénario \"Prédiction Précoce\" avec ces nouvelles features.\n",
    "- **Scénario 3 (Merge/Combine)** :\n",
    "    - Entrainement sur un jeu de données combiné (Math + Por, N=1044) avec ajout d'une feature `Subject`.\n",
    "\n",
    "### Observations / Difficultés\n",
    "- **Feature Engineering** :\n",
    "    - Impact limité. Math R2 monte légèrement à **0.259**.\n",
    "- **Dataset Combiné** :\n",
    "    - Random Forest R2 = **0.241**. RMSE = 3.426.\n",
    "    - L'augmentation du volume de données ne compense pas la difficulté intrinsèque de prédire G3 sans G1/G2.\n",
    "    - Cela confirme que la réussite scolaire dépend fortement de facteurs temporels (notes précédentes) ou non capturés par ce dataset (psychologie, contexte classe, etc.).\n",
    "\n",
    "### Conclusion Générale\n",
    "- Le modèle \"Final\" (avec G1/G2) est excellent (R2 > 0.8) et fiable pour le déploiement.\n",
    "- Le modèle \"Précoce\" (sans notes) est un indicateur faible mais peut servir à identifier des profils à risque (via `failures` et `absences`) plutôt qu'à prédire une note précise.\n",
    "- Structure de la soutenance définie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jour 5 - 16/01/2026\n",
    "\n",
    "### Étapes / Actions réalisées\n",
    "- **Audit des Modèles** : demande de validation rigoureuse des choix.\n",
    "- Création d'un protocole de benchmark (`model_benchmarking.ipynb`) : 5-fold CV sur 5 modèles (Linear, RF, LightGBM, SVR, MLP).\n",
    "- **Résultats du Benchmark** :\n",
    "    - *Scénario Final* : La Régression Linéaire (R2=0.784) bat Random Forest (0.775) et LightGBM.\n",
    "    - *Scénario Précoce* : SVR domine (R2=0.16) mais reste faible. Les réseaux de neurones (MLP) échouent (trop peu de données).\n",
    "\n",
    "### Observations / Difficultés\n",
    "- Le Deep Learning n'est pas adapté à ce volume de données (< 1000 lignes).\n",
    "- La simplicité de la régression linéaire la rend très attractive pour le déploiement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jour 6 - 17/01/2026\n",
    "\n",
    "### Étapes / Actions réalisées\n",
    "- **Test d'Ensembling** : Hypothèse que combiner Linear + RF pourrait lisser les erreurs.\n",
    "- Implémentation d'un `VotingRegressor`.\n",
    "- **Résultat** : Victoire de l'Ensemble avec **R2 = 0.795** et **RMSE = 1.59**.\n",
    "\n",
    "### Décision Finale\n",
    "- Le modèle déployé sera l'**Ensemble (Linear Regression + Random Forest)**.\n",
    "- Il offre le meilleur compromis performance/robustesse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jour 7 - 18/01/2026\n",
    "\n",
    "### Raffinements Finaux et Déploiement\n",
    "\n",
    "#### 1. Affinement du Modèle (Gestion des Abandons)\n",
    "- **Constat** : L'analyse détaillée des données a montré que les notes à 0 (pour `G3`) correspondent majoritairement à des abandons ou absences, faussant la régression pour les élèves actifs.\n",
    "- **Décision** : Le modèle déployé a été ré-entraîné sur un subset filtré (`G3 > 0`).\n",
    "- **Impact** : Meilleure précision pour les utilisateurs réels de l'application (étudiants en cours de scolarité).\n",
    "\n",
    "#### 2. Éthique et UI/UX\n",
    "- **Data Minimization** : Retrait des champs sensibles (santé, famille) de l'interface de saisie.\n",
    "- **Valeurs neutres** : Injection transparente de valeurs médianes/neutres dans l'API pour ces champs, afin de ne pas casser le modèle tout en protégeant l'utilisateur.\n",
    "- **Interface** : Adoption d'une navigation par menu latéral (`sidebar`) pour séparer clairement l'accueil des outils de prédiction.\n",
    "\n",
    "#### 3. Industrialisation (Traefik, Monitoring & MLOps)\n",
    "- **Architecture Distante** : Configuration complète de Traefik pour exposer l'API, le Frontend, Prometheus, Grafana, MLFlow et Prefect via des URLs dédiées (`*.dev.brad.team`).\n",
    "- **Monitoring Observabilité** : Dashboard Grafana connecté à Prometheus pour suivre la santé de l'API (RPS, Latence, Status Up/Down) en temps réel.\n",
    "- **Experiment Tracking (MLFlow)** : Intégration de MLFlow pour tracer chaque requête API (inputs/outputs) et versionner les modèles lors du ré-entraînement.\n",
    "- **Orchestration (Prefect)** : Mise en place de Prefect pour automatiser le pipeline de ré-entraînement (`retraining_flow`), assurant reproductibilité et gestion des flux.\n",
    "- **Optimisation Infrastructure (Debian 13)** : Configuration spécifique de cAdvisor pour supporter `cgroupv2`, garantissant une visibilité complète des métriques conteneurisées sur le serveur de production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd4c68d",
   "metadata": {},
   "source": [
    "## Choix d'Architecture de Déploiement\n",
    "\n",
    "Nous avons opté pour une stratégie de **construction locale des images conteneurisées** (CI/CD via SSH + `podman-compose build`) plutôt que l'utilisation d'un registre d'images externe (type Docker Hub ou GHCR).\n",
    "\n",
    "**Justification :**\n",
    "1.  **Spécificité de la Solution** : Contrairement à un SaaS standardisé destiné à être dupliqué à l'identique pour des milliers de clients, notre solution est une **application sur-mesure**, adaptée aux données spécifiques de l'établissement.\n",
    "2.  **Unicité du Déploiement** : Le déploiement est unique (une seule instance de production). Il n'y a pas de nécessité de distribuer des images compressées à travers un cluster complexe.\n",
    "3.  **Simplicité & Frugalité** : \n",
    "    *   Évite la gestion de secrets supplémentaires pour un registre privé.\n",
    "    *   Réduit la bande passante (pas d'upload/download d'images lourdes, seul le code source léger transite).\n",
    "    *   Les couches de cache locales de Podman sur le serveur rendent les reconstructions très rapides pour les mises à jour mineures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
